{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "genetic-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "warming-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "selected-creator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-mexico",
   "metadata": {},
   "source": [
    "# SLCP experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "educational-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulators import SLCP\n",
    "from datasets import LTEDataset\n",
    "from models import Flatten, MNRE\n",
    "from criterions import WeightedLoss, RELoss, RDLoss\n",
    "from samplers import TractableSampler, NRESampler\n",
    "from histograms import pairhist, corner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-league",
   "metadata": {},
   "source": [
    "## Simulator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "median-candidate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.4355, -1.8684,  2.5289, -0.5714, -2.0816], device='cuda:0'),\n",
       " tensor([[-13.7469,  -1.3300],\n",
       "         [  7.9673,  -2.3458],\n",
       "         [  4.1226,  -2.1861],\n",
       "         [ -0.2871,  -1.8487]], device='cuda:0'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator = SLCP().to(device)\n",
    "simulator.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accessory-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = LTEDataset(simulator, mode=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-flexibility",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "capable-pressing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  True,  True],\n",
       "        [False, False,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_subsets = torch.tensor([\n",
    "    [False, False, False, True, True],\n",
    "    [False, False, True, True, True],\n",
    "    [True, True, True, True, True]\n",
    "])\n",
    "\n",
    "joint_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "single-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNRE(masks=joint_subsets, encoder=Flatten((4, 2)), num_layers=10, hidden_size=512, activation=nn.SELU).to(device)\n",
    "criterion = WeightedLoss([RDLoss(joint_subsets)], [.01]).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, amsgrad=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=2.5e-1, patience=5, threshold=1e-2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "virtual-frost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('mnre.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-replica",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "graduate-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = simulator.low.cpu()\n",
    "high = simulator.high.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aggressive-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_star = torch.tensor([0.7, -2.9, -1., -0.9,  0.6]).to(device)\n",
    "x_star = torch.tensor([\n",
    "    [-0.48406151, -3.13977371],\n",
    "    [-0.43098274, -3.50238278],\n",
    "    [-0.03512463, -2.87554796],\n",
    "    [ 1.43279532, -2.80650507]\n",
    "]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sitting-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star = x_star.expand(2 ** 12, -1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-cholesterol",
   "metadata": {},
   "source": [
    "### Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "analyzed-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TractableSampler(simulator, x_star, sigma=0.1)\n",
    "samples = sampler(4096)\n",
    "hists_lhd = pairhist(samples, low, high, bins=60, normed=True, bounded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-heather",
   "metadata": {},
   "source": [
    "### MNRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accessible-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z_star = model.encoder(x_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-architect",
   "metadata": {},
   "source": [
    "#### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "later-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, nre = model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prerequisite-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = NRESampler(simulator.prior, nre, z_star, sigma=0.1)\n",
    "samples = sampler(4096)\n",
    "hists_all = pairhist(samples, low, high, bins=60, normed=True, bounded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "conscious-lambda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0905)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kl_divergence(p: torch.Tensor, q: torch.Tensor, epsilon: float = 1e-8) -> torch.Tensor:\n",
    "    mask = p > 0\n",
    "    \n",
    "    return (p * ((p + epsilon).log() - (q + epsilon).log())).sum()\n",
    "\n",
    "kl_divergence(hists_lhd[4][3], hists_all[4][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-poetry",
   "metadata": {},
   "source": [
    "#### 4 & 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aboriginal-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, nre = model[0]\n",
    "mask = mask.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "welcome-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = NRESampler(simulator.subprior(mask), nre, z_star, sigma=0.1)\n",
    "samples = sampler(4096)\n",
    "hists_45 = pairhist(samples, low[mask], high[mask], bins=60, normed=True, bounded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bright-trunk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2208)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(hists_lhd[4][3], hists_45[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "tough-batch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3862)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(hists_all[4][3], hists_45[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-reaction",
   "metadata": {},
   "source": [
    "#### 3, 4 & 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "extra-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, nre = model[1]\n",
    "mask = mask.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "orange-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = NRESampler(simulator.subprior(mask), nre, z_star, sigma=0.1)\n",
    "samples = sampler(4096)\n",
    "hists_345 = pairhist(samples, low[mask], high[mask], bins=60, normed=True, bounded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "found-prototype",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2821)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(hists_lhd[4][3], hists_345[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "exclusive-account",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3039)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(hists_all[4][3], hists_345[2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-converter",
   "metadata": {},
   "source": [
    "## Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "numerical-sustainability",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 6434.47998046875 +- 98648.21875\n",
      "1: 243.2634735107422 +- 2301.369384765625\n",
      "2: 107.98551940917969 +- 793.1503295898438\n",
      "3: 33.458988189697266 +- 140.18136596679688\n",
      "4: 248.1635284423828 +- 2836.357421875\n",
      "5: 82.89403533935547 +- 663.243408203125\n",
      "6: 28.50716209411621 +- 182.9430389404297\n",
      "7: 62.96383285522461 +- 375.9570617675781\n",
      "8: 103.03263092041016 +- 606.2960205078125\n",
      "9: 129.53663635253906 +- 1362.8341064453125\n",
      "10: 1564.6214599609375 +- 15017.2529296875\n",
      "11: 23812.28125 +- 379942.65625\n",
      "12: 80.72254180908203 +- 634.89208984375\n",
      "Epoch    13: reducing learning rate of group 0 to 2.5000e-06.\n",
      "13: 51644.11328125 +- 824921.3125\n",
      "14: 348.1349182128906 +- 5117.32470703125\n",
      "15: 147.636474609375 +- 1988.786376953125\n",
      "16: 191.64784240722656 +- 1178.849609375\n",
      "17: 674.4408569335938 +- 9948.1826171875\n",
      "18: 51.47740173339844 +- 270.3169860839844\n",
      "Epoch    19: reducing learning rate of group 0 to 6.2500e-07.\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "epoch = 0\n",
    "epoch_size = 256\n",
    "\n",
    "losses = []\n",
    "\n",
    "for thetas, xs, mask in trainset:\n",
    "    ratios = model(thetas, xs)\n",
    "    loss = criterion(ratios, mask)\n",
    "\n",
    "    losses.append(loss.tolist())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "    optimizer.step()\n",
    "\n",
    "    if len(losses) == epoch_size:\n",
    "        losses = torch.tensor(losses)\n",
    "\n",
    "        print(f'{epoch}: {losses.mean()} +- {losses.std()}')\n",
    "        scheduler.step(losses.mean())\n",
    "\n",
    "        epoch += 1\n",
    "        losses = []\n",
    "\n",
    "        if optimizer.param_groups[0]['lr'] < 1e-6:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-yahoo",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings\n",
    "### MNRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bibliographic-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z_star = model.encoder(x_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-living",
   "metadata": {},
   "source": [
    "#### 4 & 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "attached-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, nre = model[0]\n",
    "mask = mask.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "nutritional-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = NRESampler(simulator.subprior(mask), nre, z_star, sigma=0.1)\n",
    "samples = sampler(4096)\n",
    "hists_45 = pairhist(samples, low[mask], high[mask], bins=60, normed=True, bounded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "comfortable-valuation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2862)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(hists_lhd[4][3], hists_45[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "approximate-fifteen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2462)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(hists_all[4][3], hists_45[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-smith",
   "metadata": {},
   "source": [
    "#### 3, 4 & 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "short-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, nre = model[1]\n",
    "mask = mask.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "tough-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = NRESampler(simulator.subprior(mask), nre, z_star, sigma=0.1)\n",
    "samples = sampler(4096)\n",
    "hists_345 = pairhist(samples, low[mask], high[mask], bins=60, normed=True, bounded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "approximate-operations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1876)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(hists_lhd[4][3], hists_345[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "composite-repository",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1468)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(hists_all[4][3], hists_345[2][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
